<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Drifting Ruby</title>
  <subtitle>Collection of ideas about programming, screencasts, Ruby on Rails, and more.</subtitle>
  <id>https://blog.driftingruby.com/articles</id>
  <link href="https://blog.driftingruby.com/articles"/>
  <link href="https://blog.driftingruby.com/feed.xml" rel="self"/>
  <updated>2023-05-05T20:00:00-04:00</updated>
  <author>
    <name>Dave Kimura</name>
  </author>
  <entry>
    <title>Running Meilisearch</title>
    <link rel="alternate" href="https://blog.driftingruby.com/articles/2023/05/06/running-meilisearch.html"/>
    <id>https://blog.driftingruby.com/articles/2023/05/06/running-meilisearch.html</id>
    <published>2023-05-05T20:00:00-04:00</published>
    <updated>2023-09-30T22:29:56-04:00</updated>
    <author>
      <name>Dave Kimura</name>
    </author>
    <content type="html">&lt;p&gt;MeiliSearch is a powerful, fast, and easy-to-use search engine, perfect for developers who want to implement search functionality into their applications. In this blog post, we will walk you through the process of deploying MeiliSearch with SSL encryption using Docker Compose and Nginx as a reverse proxy. This setup ensures a secure connection between your users and your MeiliSearch instance.&lt;/p&gt;

&lt;h2 id="prerequisites"&gt;Prerequisites&lt;/h2&gt;

&lt;p&gt;Before you begin, make sure you have the following tools installed on your system:&lt;/p&gt;

&lt;p&gt;Docker: Ensure Docker is installed and running on your machine. You can follow the installation guide on the official Docker website.&lt;/p&gt;

&lt;p&gt;Docker Compose: Make sure Docker Compose is installed. You can find installation instructions on the official Docker Compose website.&lt;/p&gt;

&lt;p&gt;OpenSSL: Required for generating SSL certificates. You can install OpenSSL through your package manager or download it from the official OpenSSL website.&lt;/p&gt;

&lt;h2 id="configuration"&gt;Configuration&lt;/h2&gt;

&lt;p&gt;Create a docker-compose.yml file in your project directory and copy the following content:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;version: '3.8'

services:
  meilisearch:
    image: getmeili/meilisearch:v1.1
    restart: always
    ports:
      - '7700:7700'
    environment:
      - MEILI_MASTER_KEY=key
    volumes:
      - meili_data:/meili_data

  nginx:
    image: nginx:stable-alpine
    restart: always
    ports:
      - '80:80'
      - '443:443'
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - /home/ubuntu/cert.pem:/etc/nginx/certs/fullchain.pem
      - /home/ubuntu/key.pem:/etc/nginx/certs/privkey.pem
    depends_on:
      - meilisearch

volumes:
  meili_data:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This configuration file sets up two services: MeiliSearch and Nginx.&lt;/p&gt;

&lt;h2 id="meilisearch-service"&gt;Meilisearch service:&lt;/h2&gt;

&lt;p&gt;You should replace the key value with a random string. This key will be used to secure your MeiliSearch instance. You can generate a random string using the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;openssl rand -hex 16
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id="nginx-service"&gt;Nginx service:&lt;/h2&gt;

&lt;p&gt;There's a bit more config to do with the Nginx service. We can create a ssl certificate using OpenSSL. We will use this certificate to enable SSL encryption for our MeiliSearch instance. You can generate a self-signed certificate using the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365 -subj "/CN=yourdomainname" -nodes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we can create a configuration file called nginx.conf and copy the following content:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;events {
    worker_connections 1024;
}
http {
    server {
        listen 80;
        server_name yourdomainname;
        return 301 https://$host$request_uri;
    }
    server {
        listen 443 ssl;
        server_name yourdomainname;
        ssl_certificate /etc/nginx/certs/fullchain.pem;
        ssl_certificate_key /etc/nginx/certs/privkey.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers 'TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384';
        location / {
            proxy_pass http://meilisearch:7700;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You'll want to update the appropriate values for your domain name and SSL certificate paths.&lt;/p&gt;

&lt;h2 id="running-the-application"&gt;Running the application&lt;/h2&gt;

&lt;p&gt;Now that we have our configuration files ready, we can run the application using the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker compose up -d
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will start both services in the background. You can check the status of your services using the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker compose ps
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You should see something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Name                Command               State           Ports
--------------------------------------------------------------------------------
meilisearch         ...                   Up              ..
nginx               ...                   Up              ..
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;-d&lt;/code&gt; in the &lt;code&gt;docker compose up -d&lt;/code&gt; command tells Docker to run the services in the background.&lt;/p&gt;

&lt;p&gt;This will also cause the services to restart automatically if they crash or if you reboot the machine.&lt;/p&gt;

&lt;p&gt;Thanks for reading!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Ruby 3.2.1 with YJIT</title>
    <link rel="alternate" href="https://blog.driftingruby.com/articles/2023/03/04/ruby-with-yjit.html"/>
    <id>https://blog.driftingruby.com/articles/2023/03/04/ruby-with-yjit.html</id>
    <published>2023-03-03T19:00:00-05:00</published>
    <updated>2023-03-04T23:34:53-05:00</updated>
    <author>
      <name>Dave Kimura</name>
    </author>
    <content type="html">&lt;p&gt;I've been using Ruby 3.2.1 + YJIT for some time now and overall, I'm seeing anywhere from 10-20%
performance improvements over running Ruby 3.0.5. Sorry, I don't have an apple-to-apple
comparison for just YJIT vs non-YJIT. However, the performance improvements are real world
scenarios on a Ruby on Rails 7.0.4 application.&lt;/p&gt;

&lt;p&gt;So, I've recently formatted my primary desktop which is running macOS 13.2.1 and figured that
I would document my steps on my preferred way of installing Ruby as well as getting YJIT to work.
It's important to note that this is also an Apple Silicon machine. These steps should work regardless
of which Apple Silicon you're using.&lt;/p&gt;

&lt;p&gt;First, I'll install homebrew. This will automatically install the Command Line Tools for Xcode.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You'll then be prompted to run some additional commands.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(echo; echo 'eval "$(/opt/homebrew/bin/brew shellenv)"') &amp;gt;&amp;gt; /Users/$(whoami)/.zprofile
eval "$(/opt/homebrew/bin/brew shellenv)"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then start our install of Ruby. However, there are a few things that we should do first.
Firstly, we need to select a manager for our Ruby interpreter. I normally use RVM as it's what
I used for the longest time. It works well and I never had any complaints. However, with Ruby
3.2.1, we're also going to need an installation of Rust if we want to enable YJIT. So, instead
of RVM, I'm going to be using ASDF.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;brew install asdf
echo -e "\n. $(brew --prefix asdf)/libexec/asdf.sh" &amp;gt;&amp;gt; ${ZDOTDIR:-~}/.zshrc
source ~/.zshrc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that we have a manager for our Ruby and Rust, we can now proceed to install Rust.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;asdf plugin add rust
asdf install rust latest
asdf global rust latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that Rust is installed, we can proceed with our Ruby installation. Normally there are some
dependencies that we need to handle, but luckily, asdf will take care of that for us.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;asdf plugin add ruby
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, there is a strange thing with the mapping of the libraries so if we were to try and
install Ruby right now, it would fail. So let's take care of this. This is around the libyaml
package and we need to set some environment variables for this. I've added all four of these
to my ~/.zshrc so that Ruby can install properly and YJIT is enabled out of the box.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;brew install openssl@3 readline libyaml gmp
echo 'export LDFLAGS="-L$(brew --prefix libyaml)/lib"' &amp;gt;&amp;gt; ~/.zshrc
echo 'export CPPFLAGS="-I$(brew --prefix libyaml)/include"' &amp;gt;&amp;gt; ~/.zshrc
echo 'export RUBY_YJIT_ENABLE=1' &amp;gt;&amp;gt; ~/.zshrc
echo 'export RUBY_CONFIGURE_OPTS=--enable-yjit' &amp;gt;&amp;gt; ~/.zshrc
source ~/.zshrc
asdf install ruby 3.2.1
asdf global ruby 3.2.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I had to restart my terminal, but once I did, everything seemed to work as expected.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ruby -v
ruby 3.2.1 (2023-02-08 revision 31819e82c8) +YJIT [arm64-darwin22]
&lt;/code&gt;&lt;/pre&gt;
</content>
  </entry>
  <entry>
    <title>Pushing Code to Multiple Repositories with Git</title>
    <link rel="alternate" href="https://blog.driftingruby.com/articles/2023/02/23/pushing-to-multiple-repositories.html"/>
    <id>https://blog.driftingruby.com/articles/2023/02/23/pushing-to-multiple-repositories.html</id>
    <published>2023-02-22T19:00:00-05:00</published>
    <updated>2023-02-23T11:30:44-05:00</updated>
    <author>
      <name>Dave Kimura</name>
    </author>
    <content type="html">&lt;p&gt;Have you ever found yourself needing to publish your code to multiple repositories? Perhaps you have a static site hosted on Github Pages and want to have multiple domains point to it. Or maybe you manage multiple technology-related blogs and need to consolidate your content into a single blog, while still updating it on multiple domain names. In this article, we will explore a solution to push code to multiple repositories with minimal effort using Git.&lt;/p&gt;

&lt;p&gt;As mentioned earlier, there are scenarios where you need to update your code on multiple repositories, and doing so manually can be time-consuming and error-prone. For instance, you may have a blog that you want to host on multiple domains, but instead of redirecting users to a new site, you prefer to update the content on both domains simultaneously. In such cases, you can use Git to push changes to multiple repositories with just a few commands.&lt;/p&gt;

&lt;p&gt;To push code to multiple repositories, you first need to initialize your Git repository and push the changes to one of the repositories. In our example, let's say we push the changes to the repository kobaltz/blog-kobaltz.git. Now, we want to push the same code to another repository kobaltz/blog-driftingruby.git. To achieve this, we can add another push URL to our .git/config file using the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git remote set-url --add --push origin git@github.com:kobaltz/blog-driftingruby.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command adds a new push URL to the origin remote and sets it to the git@github.com:kobaltz/blog-driftingruby.git repository. Now, whenever you commit your changes and push them, Git will push the changes to both repositories.&lt;/p&gt;

&lt;p&gt;You can verify that the push URL has been added by running the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git remote -v
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This command will display the two push URLs under the origin remote, as shown below:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;origin  git@github.com:kobaltz/blog-kimura.git (fetch)
origin  git@github.com:kobaltz/blog-kimura.git (push)
origin  git@github.com:kobaltz/blog-driftingruby.git (push)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, your code is being pushed to two repositories with minimal effort. If you ever want to remove one of the push URLs, you can do so by using the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git remote set-url --delete --push origin git@github.com:kobaltz/blog-driftingruby.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this article, we've explored a simple solution to push code to multiple repositories using Git. By adding a new push URL to the origin remote, we can push changes to multiple repositories with minimal effort. This technique can be useful in scenarios where you need to update your code on multiple domains or repositories. And, remember that you can use different services as well for the push URLs; one pointing to
GitHub and another pointing to GitLab.&lt;/p&gt;

&lt;p&gt;By consolidating your code base and keeping multiple repositories up to date, you can simplify your workflow and save time. Give this approach a try and see how it works for you. Happy coding!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Docker Builds are slow on M1</title>
    <link rel="alternate" href="https://blog.driftingruby.com/articles/2022/04/09/docker-builds-are-slow-on-m1.html"/>
    <id>https://blog.driftingruby.com/articles/2022/04/09/docker-builds-are-slow-on-m1.html</id>
    <published>2022-04-08T20:00:00-04:00</published>
    <updated>2023-02-18T01:05:28-05:00</updated>
    <author>
      <name>Dave Kimura</name>
    </author>
    <content type="html">&lt;p&gt;This is a neat Docker trick for those who have an ARM development machine (Apple M1), but sometimes need to build x86/amd64 images locally to push up to a registry.&lt;/p&gt;

&lt;p&gt;Sure, having a CI/CD platform to do this is probably ideal, but for little programs or just sometimes in general, it may be handy to know this.&lt;/p&gt;

&lt;p&gt;If you have a spare Intel machine laying around, you can turn it into a build server. Get something like &lt;a href="https://docs.docker.com/engine/install/ubuntu/"&gt;Ubuntu installed&lt;/a&gt; on there and install the latest Docker. On your development machine, &lt;a href="https://www.ssh.com/academy/ssh/copy-id"&gt;copy your publish SSH key over to this build server.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So now you you have your server set up and you want to build your Docker image for an x86/amd64 platform. Typically, you would run a command like this below to target the platform.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker buildx build -f Dockerfile --platform linux/amd64 .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And this will work, but what you'll notice is that this is an extremely slow process. The Apple Silicon chips are amazing and are the fastest machines I've ever used. However, when emulating the x86 instructions to build a docker image, it takes such a long time. I've seen this take over an hour on larger and more complex projects.&lt;/p&gt;

&lt;p&gt;Just as an example. Here we have a very simple Ruby on Rails application that has little moving parts. I'm using things like &lt;code&gt;esbuild&lt;/code&gt; and &lt;code&gt;css-bundling&lt;/code&gt;, but nothing fancy. On the M1 chip, it took over 250 seconds to build the image.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Apple Silicon
[+] Building 316.4s (23/23) FINISHED
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;However, on a AMD 5900X server, I have a Virtual Machine running on there which has Docker installed. Running the exact same project on there took much less time.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# AMD 5900X
[+] Building 62.3s (24/24) FINISHED
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So, the main concern here is that I do not want to interrupt my normal process on how I build images or handle things. It would be a pain to push up my code, ssh into the build server, pull it down, and then build the image. This is a lot of steps, but luckily there is a MUCH easier way to do this.&lt;/p&gt;

&lt;p&gt;Docker's buildx build command has a flag that we can specify a specific builder.&lt;/p&gt;

&lt;p&gt;So, we can create this builder on our local machine. The nice part about this creation is that it is idempotent, so you can run this command many times without changing the result. All we have to do is to create a builder profile and in this case I have named it &lt;code&gt;amd64_builder&lt;/code&gt;.  Since this builder is a pool of resources, I give a name to for the VM. I'm also specifying the platform that I'm building against and then pass in the SSH url for my builder machine.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker buildx create \
  --name amd64_builder \
  --node linux_amd64_builder \
  --platform linux/amd64 \
  ssh://USERNAME@IP_ADDRESS_OF_BUILDER
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, I can build and push the image to the registry. The magical flag that we'll use is &lt;code&gt;--builder&lt;/code&gt; as we can now specify the builder VM. The rest of the buildx command is the same as we would expect.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker buildx build \
  --builder amd64_builder \
  --tag USERNAME/REPONAME:TAG \
  --push .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In some cases, I've seen this go almost 10x faster than the amd64 emulation on the M1 chip. If you have a spare Intel/AMD machine laying around, this may be a worthwhile adventure.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Transferring Files</title>
    <link rel="alternate" href="https://blog.driftingruby.com/articles/2022/04/08/transferring-files.html"/>
    <id>https://blog.driftingruby.com/articles/2022/04/08/transferring-files.html</id>
    <published>2022-04-07T20:00:00-04:00</published>
    <updated>2023-02-18T01:04:07-05:00</updated>
    <author>
      <name>Dave Kimura</name>
    </author>
    <content type="html">&lt;p&gt;Sometimes we get into situations where we need to remotely transfer a file. This file could be large or it could be tiny. This file may be sensitive or could be of little importance. Regardless, sending this file over to a remote location could still have its challenges. What if the file is coming from a headless server? Perhaps you have some logs that you want to inspect on your local machine instead of parsing through them remotely in an ssh session. This is where &lt;a href="https://magic-wormhole.readthedocs.io"&gt;magic-wormhole&lt;/a&gt; comes into play.&lt;/p&gt;

&lt;h2 id="installation"&gt;Installation&lt;/h2&gt;

&lt;h3 id="macos"&gt;macOS&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;brew install magic-wormhole&lt;/code&gt;&lt;/p&gt;

&lt;h3 id="linux-debianubuntu"&gt;Linux (Debian/Ubuntu)&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;sudo apt install magic-wormhole&lt;/code&gt;&lt;/p&gt;

&lt;h2 id="usage"&gt;Usage&lt;/h2&gt;

&lt;p&gt;To send a file, you simply use the wormhole command and specify which file you wish to send.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;➜  ~ wormhole send server.log
Sending 1.1 GB file named 'server.log'
Wormhole code is: 5-hydraulic-snowslide
On the other computer, please run:

wormhole receive 5-hydraulic-snowslide
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that we have specified which file we want to send, we've been provided with a "wormhole code" that we can use on the receiving end.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wormhole receive 5-hydraulic-snowslide
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And that's all we have to do! On the receiving computer, we've downloaded the requested file! In the past, I would have used &lt;code&gt;scp&lt;/code&gt; or &lt;code&gt;ftp&lt;/code&gt; but remembering the syntax, while isn't too difficult, can prove to be challenging at times especially if nonstandard ports are used or if ports aren't opened up on the firewall to make the connection.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;➜  ~ wormhole receive 5-hydraulic-snowslide
Receiving file (1.1 GB) into: server.log
ok? (y/N): y
Receiving (-&amp;gt;tcp:some-external-ip:65250)..
 80%|█████████████████▏               | 859M/1.07G [00:04&amp;lt;00:01, 206MB/s]
&lt;/code&gt;&lt;/pre&gt;
</content>
  </entry>
  <entry>
    <title>Let's Encrypt Wildcard Cert</title>
    <link rel="alternate" href="https://blog.driftingruby.com/articles/2021/02/10/lets-encrypt-wildcard-cert.html"/>
    <id>https://blog.driftingruby.com/articles/2021/02/10/lets-encrypt-wildcard-cert.html</id>
    <published>2021-02-09T19:00:00-05:00</published>
    <updated>2023-02-18T01:02:12-05:00</updated>
    <author>
      <name>Dave Kimura</name>
    </author>
    <content type="html">&lt;p&gt;I'm writing this more as documentation for myself as I have several domains which I often use as playgrounds for certain things. This could be a kubernetes environment or a docker cluster where I have several applications deployed, but don't want to set up an nginx site for each one of the apps that I deploy.&lt;/p&gt;

&lt;p&gt;Recently, I found out about Portainer for managing a docker environment. Think of this as a kubernetes-lite. This isn't good for any kind of production use case, but does have some benefits for at home management of a local docker instance.&lt;/p&gt;

&lt;p&gt;&lt;img src="/articles/2021/02/10/lets-encrypt-wildcard-cert/PNG-image-90C9A493911C-1.png" alt="" /&gt;&lt;/p&gt;

&lt;p&gt;So in this illustration, we have a request coming in on 443. This request could be using the domain name &lt;code&gt;c1.mydomain.com&lt;/code&gt; and there could be another request coming in from &lt;code&gt;c2.mydomain.com&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Previously, you would have a certificate for both subdomains and would need to set up the appropriate port forwarding for each subdomain to the appropriate server. This is a huge pain, so, instead, this is where a wildcard certificate can come in handy.&lt;/p&gt;

&lt;p&gt;In this particular scenario, I have an nginx proxy which will be used to route all of the traffic coming in to my network. This is handy because I can use this reverse proxy for SSL termination and also routing the traffic to various servers based on the domain name. This doesn't have to be a powerful server. You could even use a Raspberry Pi to route this traffic. Again, this is for a home server and not really production grade.&lt;/p&gt;

&lt;p&gt;You will need some prerequisites. And I also use CloudFlare's DNS for handling these wildcard domains. This is nice because certbot and cloudflare play pretty nicely to automatically verify the challenges via their API.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apt install certbot letsencrypt python3-certbot-dns-cloudflare
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you already have certbot and the necessary extensions installed, you can simply run this script to get a wildcard certificate.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo certbot certonly \
     --cert-name mydomain.com \
     --dns-cloudflare \
     --dns-cloudflare-credentials /etc/letsencrypt/cloudflareapi.cfg \
     --server https://acme-v02.api.letsencrypt.org/directory \
     -d "*.mydomain.com" \
     -d mydomain.com
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So, now we can configure our nginx proxy to take any request from this domain and forward it over to my docker host.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;server {
  server_name *.mydomain.com;
  server_name ~^(?&amp;lt;subdomain&amp;gt;.+)\.mydomain\.com$;
  add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
  # proxy_next_upstream error timeout http_502;
  location / {
    proxy_pass http://DOCKER_HOST_IP_ADDRESS;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection $connection_upgrade;
    proxy_buffering off;
  }
  listen 443 ssl;
  ssl_certificate /etc/letsencrypt/live/mydomain.com/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/mydomain.com/privkey.pem;
  include /etc/letsencrypt/options-ssl-nginx.conf;
  ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;
}

server {
  return 301 https://$host$request_uri;
  listen 80 ;
  listen [::]:80 ;
  server_name *.mydomain.com;
  server_name ~^(?&amp;lt;subdomain&amp;gt;.+)\.mydomain\.com$;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In another blog article, I'll describe how I set up the Docker host to take in these requests from the nginx server.&lt;/p&gt;
</content>
  </entry>
</feed>
